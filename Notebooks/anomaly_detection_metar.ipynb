{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4395a721",
   "metadata": {},
   "source": [
    "# ‚úàÔ∏è Aviation Weather Anomaly Detection\n",
    "## üéØ Objective: Detect Abnormal or Rare Weather Conditions\n",
    "\n",
    "**Dataset:** METAR Weather Data  \n",
    "**Model:** Isolation Forest (Unsupervised ML)  \n",
    "**Purpose:** Aviation Safety - Identify unusual weather patterns that could pose risks\n",
    "\n",
    "### Why Isolation Forest?\n",
    "- ‚úÖ Designed specifically for anomaly detection\n",
    "- ‚úÖ No labels required (unsupervised)\n",
    "- ‚úÖ Efficient with high-dimensional data\n",
    "- ‚úÖ Highly relevant for aviation safety"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d87f81",
   "metadata": {},
   "source": [
    "## üì¶ Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e67b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a966a81",
   "metadata": {},
   "source": [
    "## üìä Load METAR Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee534b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('datasets/metar.csv')\n",
    "\n",
    "print(f\"Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nColumns: {df.columns.tolist()}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7da701",
   "metadata": {},
   "source": [
    "## üîç Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "372ca46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data info\n",
    "print(\"=\" * 60)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 60)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e38804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "missing_data = pd.DataFrame({\n",
    "    'Column': df.columns,\n",
    "    'Missing_Count': df.isnull().sum(),\n",
    "    'Missing_Percentage': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "}).sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "print(missing_data[missing_data['Missing_Count'] > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78249f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary of numerical features\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"STATISTICAL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d43dbc",
   "metadata": {},
   "source": [
    "## üßπ Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0931647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant numerical features for anomaly detection\n",
    "# Focus on key weather parameters that affect aviation safety\n",
    "feature_columns = [\n",
    "    'tmpf',      # Temperature (¬∞F)\n",
    "    'dwpf',      # Dew Point (¬∞F)\n",
    "    'relh',      # Relative Humidity (%)\n",
    "    'drct',      # Wind Direction (degrees)\n",
    "    'sknt',      # Wind Speed (knots)\n",
    "    'p01i',      # Precipitation (inches)\n",
    "    'alti',      # Altimeter Setting\n",
    "    'vsby',      # Visibility (miles)\n",
    "]\n",
    "\n",
    "# Create a copy for processing\n",
    "df_processed = df[feature_columns].copy()\n",
    "\n",
    "print(f\"Selected Features: {feature_columns}\")\n",
    "print(f\"\\nShape before cleaning: {df_processed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a348b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "# For weather data, we'll use median imputation as it's robust to outliers\n",
    "for col in df_processed.columns:\n",
    "    if df_processed[col].isnull().sum() > 0:\n",
    "        median_value = df_processed[col].median()\n",
    "        df_processed[col].fillna(median_value, inplace=True)\n",
    "        print(f\"Filled {col} missing values with median: {median_value:.2f}\")\n",
    "\n",
    "print(f\"\\nShape after cleaning: {df_processed.shape}\")\n",
    "print(f\"Missing values remaining: {df_processed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf730e5",
   "metadata": {},
   "source": [
    "## üìà Visualize Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of all features\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 12))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(df_processed.columns):\n",
    "    axes[idx].hist(df_processed[col], bins=50, color='skyblue', edgecolor='black', alpha=0.7)\n",
    "    axes[idx].set_title(f'{col} Distribution', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_distributions.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ Feature distributions plotted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611c27fb",
   "metadata": {},
   "source": [
    "## üîß Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3dde2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features (important for Isolation Forest)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df_processed)\n",
    "\n",
    "# Convert back to DataFrame for better interpretability\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=df_processed.columns, index=df_processed.index)\n",
    "\n",
    "print(\"‚úÖ Features scaled using StandardScaler\")\n",
    "print(f\"\\nScaled data shape: {df_scaled.shape}\")\n",
    "print(f\"\\nScaled data statistics:\")\n",
    "df_scaled.describe().round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2387966a",
   "metadata": {},
   "source": [
    "## ü§ñ Train Isolation Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e3161f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Isolation Forest\n",
    "# contamination: expected proportion of anomalies (typically 5-10% for weather data)\n",
    "# random_state: for reproducibility\n",
    "iso_forest = IsolationForest(\n",
    "    contamination=0.05,  # Expect ~5% anomalies\n",
    "    random_state=42,\n",
    "    n_estimators=100,\n",
    "    max_samples='auto',\n",
    "    max_features=1.0,\n",
    "    bootstrap=False,\n",
    "    n_jobs=-1,  # Use all CPU cores\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"üîß Training Isolation Forest Model...\")\n",
    "print(f\"Parameters:\")\n",
    "print(f\"  - Contamination: {iso_forest.contamination}\")\n",
    "print(f\"  - Number of estimators: {iso_forest.n_estimators}\")\n",
    "print(f\"  - Random state: {iso_forest.random_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5c87a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model and predict\n",
    "predictions = iso_forest.fit_predict(df_scaled)\n",
    "anomaly_scores = iso_forest.score_samples(df_scaled)\n",
    "\n",
    "# Add predictions to original dataframe\n",
    "# -1 for anomalies, 1 for normal points\n",
    "df['anomaly'] = predictions\n",
    "df['anomaly_score'] = anomaly_scores\n",
    "\n",
    "# Create a binary flag (0 = normal, 1 = anomaly)\n",
    "df['is_anomaly'] = (predictions == -1).astype(int)\n",
    "\n",
    "print(\"‚úÖ Model training completed!\")\n",
    "print(f\"\\nTotal observations: {len(df)}\")\n",
    "print(f\"Normal points: {(predictions == 1).sum()}\")\n",
    "print(f\"Anomalies detected: {(predictions == -1).sum()}\")\n",
    "print(f\"Anomaly percentage: {(predictions == -1).sum() / len(df) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e53531d",
   "metadata": {},
   "source": [
    "## üìä Anomaly Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b64e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical comparison between normal and anomalous weather\n",
    "print(\"=\" * 80)\n",
    "print(\"NORMAL vs ANOMALOUS WEATHER CONDITIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for col in feature_columns:\n",
    "    normal_mean = df[df['is_anomaly'] == 0][col].mean()\n",
    "    anomaly_mean = df[df['is_anomaly'] == 1][col].mean()\n",
    "    \n",
    "    print(f\"\\n{col}:\")\n",
    "    print(f\"  Normal Mean: {normal_mean:.2f}\")\n",
    "    print(f\"  Anomaly Mean: {anomaly_mean:.2f}\")\n",
    "    print(f\"  Difference: {abs(normal_mean - anomaly_mean):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show top 10 most anomalous weather conditions\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOP 10 MOST ANOMALOUS WEATHER CONDITIONS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "anomalies = df[df['is_anomaly'] == 1].sort_values('anomaly_score')\n",
    "top_anomalies = anomalies.head(10)\n",
    "\n",
    "display_cols = ['valid', 'tmpf', 'dwpf', 'relh', 'sknt', 'vsby', 'p01i', 'anomaly_score']\n",
    "top_anomalies[display_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb977bff",
   "metadata": {},
   "source": [
    "## üìâ Visualize Anomaly Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07533a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot anomaly score distribution\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(df[df['is_anomaly'] == 0]['anomaly_score'], bins=50, \n",
    "         alpha=0.7, label='Normal', color='green', edgecolor='black')\n",
    "plt.hist(df[df['is_anomaly'] == 1]['anomaly_score'], bins=50, \n",
    "         alpha=0.7, label='Anomaly', color='red', edgecolor='black')\n",
    "plt.xlabel('Anomaly Score', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.title('Distribution of Anomaly Scores', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([df[df['is_anomaly'] == 0]['anomaly_score'], \n",
    "             df[df['is_anomaly'] == 1]['anomaly_score']],\n",
    "            labels=['Normal', 'Anomaly'])\n",
    "plt.ylabel('Anomaly Score', fontsize=12)\n",
    "plt.title('Anomaly Score Comparison', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_scores.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac9ee74",
   "metadata": {},
   "source": [
    "## üé® 2D Visualization using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cea654",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA for 2D visualization\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X_pca = pca.fit_transform(df_scaled)\n",
    "\n",
    "# Add PCA components to dataframe\n",
    "df['PC1'] = X_pca[:, 0]\n",
    "df['PC2'] = X_pca[:, 1]\n",
    "\n",
    "print(f\"Explained variance ratio:\")\n",
    "print(f\"  PC1: {pca.explained_variance_ratio_[0]:.2%}\")\n",
    "print(f\"  PC2: {pca.explained_variance_ratio_[1]:.2%}\")\n",
    "print(f\"  Total: {pca.explained_variance_ratio_.sum():.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f710a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "plt.figure(figsize=(14, 8))\n",
    "\n",
    "# Plot normal points\n",
    "normal_points = df[df['is_anomaly'] == 0]\n",
    "plt.scatter(normal_points['PC1'], normal_points['PC2'], \n",
    "           c='green', s=20, alpha=0.5, label='Normal', edgecolors='none')\n",
    "\n",
    "# Plot anomalies\n",
    "anomaly_points = df[df['is_anomaly'] == 1]\n",
    "plt.scatter(anomaly_points['PC1'], anomaly_points['PC2'], \n",
    "           c='red', s=100, alpha=0.8, label='Anomaly', marker='X', edgecolors='darkred', linewidth=1.5)\n",
    "\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.1%} variance)', fontsize=12)\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.1%} variance)', fontsize=12)\n",
    "plt.title('Weather Anomaly Detection - PCA Visualization', fontsize=16, fontweight='bold')\n",
    "plt.legend(fontsize=11, loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('anomaly_pca_visualization.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"‚úÖ PCA visualization completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38459335",
   "metadata": {},
   "source": [
    "## üìç Feature-wise Anomaly Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c88145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create box plots for each feature comparing normal vs anomaly\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15, 14))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(feature_columns):\n",
    "    data_to_plot = [df[df['is_anomaly'] == 0][col].dropna(), \n",
    "                    df[df['is_anomaly'] == 1][col].dropna()]\n",
    "    \n",
    "    bp = axes[idx].boxplot(data_to_plot, labels=['Normal', 'Anomaly'],\n",
    "                           patch_artist=True, showmeans=True)\n",
    "    \n",
    "    # Color the boxes\n",
    "    bp['boxes'][0].set_facecolor('lightgreen')\n",
    "    bp['boxes'][1].set_facecolor('lightcoral')\n",
    "    \n",
    "    axes[idx].set_title(f'{col}', fontsize=12, fontweight='bold')\n",
    "    axes[idx].set_ylabel('Value', fontsize=10)\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('Feature Comparison: Normal vs Anomalous Weather', \n",
    "             fontsize=16, fontweight='bold', y=1.00)\n",
    "plt.tight_layout()\n",
    "plt.savefig('feature_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec51ce4",
   "metadata": {},
   "source": [
    "## üå°Ô∏è Temperature vs Visibility Anomaly Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07acd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Temperature vs Visibility (critical aviation parameters)\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.scatter(df[df['is_anomaly'] == 0]['tmpf'], \n",
    "           df[df['is_anomaly'] == 0]['vsby'],\n",
    "           c='green', s=30, alpha=0.5, label='Normal', edgecolors='none')\n",
    "\n",
    "plt.scatter(df[df['is_anomaly'] == 1]['tmpf'], \n",
    "           df[df['is_anomaly'] == 1]['vsby'],\n",
    "           c='red', s=120, alpha=0.8, label='Anomaly', \n",
    "           marker='X', edgecolors='darkred', linewidth=1.5)\n",
    "\n",
    "plt.xlabel('Temperature (¬∞F)', fontsize=12)\n",
    "plt.ylabel('Visibility (miles)', fontsize=12)\n",
    "plt.title('Temperature vs Visibility: Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('temp_vs_visibility.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfadcc0f",
   "metadata": {},
   "source": [
    "## üí® Wind Speed vs Precipitation Anomaly Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8b5f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Wind Speed vs Precipitation\n",
    "plt.figure(figsize=(12, 7))\n",
    "\n",
    "plt.scatter(df[df['is_anomaly'] == 0]['sknt'], \n",
    "           df[df['is_anomaly'] == 0]['p01i'],\n",
    "           c='green', s=30, alpha=0.5, label='Normal', edgecolors='none')\n",
    "\n",
    "plt.scatter(df[df['is_anomaly'] == 1]['sknt'], \n",
    "           df[df['is_anomaly'] == 1]['p01i'],\n",
    "           c='red', s=120, alpha=0.8, label='Anomaly', \n",
    "           marker='X', edgecolors='darkred', linewidth=1.5)\n",
    "\n",
    "plt.xlabel('Wind Speed (knots)', fontsize=12)\n",
    "plt.ylabel('Precipitation (inches)', fontsize=12)\n",
    "plt.title('Wind Speed vs Precipitation: Anomaly Detection', fontsize=14, fontweight='bold')\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig('wind_vs_precipitation.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d203e94e",
   "metadata": {},
   "source": [
    "## üìà Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c50bd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for features\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "correlation_matrix = df_processed.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.title('Feature Correlation Heatmap', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_heatmap.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8905c999",
   "metadata": {},
   "source": [
    "## üìã Anomaly Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915abbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate comprehensive summary\n",
    "print(\"=\"*80)\n",
    "print(\"ANOMALY DETECTION SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä Dataset Overview:\")\n",
    "print(f\"   Total Weather Observations: {len(df):,}\")\n",
    "print(f\"   Date Range: {df['valid'].min()} to {df['valid'].max()}\")\n",
    "print(f\"   Station(s): {df['station'].unique().tolist()}\")\n",
    "\n",
    "print(f\"\\nüéØ Model Configuration:\")\n",
    "print(f\"   Algorithm: Isolation Forest\")\n",
    "print(f\"   Contamination Rate: {iso_forest.contamination*100}%\")\n",
    "print(f\"   Number of Trees: {iso_forest.n_estimators}\")\n",
    "print(f\"   Features Used: {len(feature_columns)}\")\n",
    "\n",
    "print(f\"\\nüîç Detection Results:\")\n",
    "print(f\"   Normal Observations: {(df['is_anomaly'] == 0).sum():,} ({(df['is_anomaly'] == 0).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"   Anomalies Detected: {(df['is_anomaly'] == 1).sum():,} ({(df['is_anomaly'] == 1).sum()/len(df)*100:.2f}%)\")\n",
    "print(f\"   Average Anomaly Score (Normal): {df[df['is_anomaly'] == 0]['anomaly_score'].mean():.4f}\")\n",
    "print(f\"   Average Anomaly Score (Anomaly): {df[df['is_anomaly'] == 1]['anomaly_score'].mean():.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö†Ô∏è Aviation Safety Insights:\")\n",
    "low_visibility_anomalies = df[(df['is_anomaly'] == 1) & (df['vsby'] < 3)]\n",
    "high_wind_anomalies = df[(df['is_anomaly'] == 1) & (df['sknt'] > 20)]\n",
    "heavy_precip_anomalies = df[(df['is_anomaly'] == 1) & (df['p01i'] > 0.1)]\n",
    "\n",
    "print(f\"   Low Visibility Anomalies (<3 miles): {len(low_visibility_anomalies)}\")\n",
    "print(f\"   High Wind Anomalies (>20 knots): {len(high_wind_anomalies)}\")\n",
    "print(f\"   Heavy Precipitation Anomalies (>0.1 in): {len(heavy_precip_anomalies)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ccb8f95",
   "metadata": {},
   "source": [
    "## üíæ Save Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef5f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save anomalies to CSV\n",
    "anomaly_df = df[df['is_anomaly'] == 1].sort_values('anomaly_score')\n",
    "anomaly_df.to_csv('detected_anomalies.csv', index=False)\n",
    "\n",
    "print(f\"‚úÖ Saved {len(anomaly_df)} anomalies to 'detected_anomalies.csv'\")\n",
    "\n",
    "# Save full dataset with predictions\n",
    "df.to_csv('metar_with_anomalies.csv', index=False)\n",
    "print(f\"‚úÖ Saved full dataset with predictions to 'metar_with_anomalies.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946d9ae0",
   "metadata": {},
   "source": [
    "## üéØ Key Findings & Recommendations\n",
    "\n",
    "### Model Performance\n",
    "- ‚úÖ Isolation Forest successfully identified rare weather patterns\n",
    "- ‚úÖ Unsupervised approach requires no labeled training data\n",
    "- ‚úÖ Scalable for real-time aviation weather monitoring\n",
    "\n",
    "### Aviation Safety Applications\n",
    "1. **Pre-flight Planning**: Identify potentially hazardous weather conditions\n",
    "2. **Real-time Alerts**: Flag unusual weather patterns for pilot awareness\n",
    "3. **Route Optimization**: Avoid areas with anomalous weather\n",
    "4. **Maintenance Scheduling**: Detect extreme conditions affecting aircraft\n",
    "\n",
    "### Next Steps\n",
    "- [ ] Fine-tune contamination parameter based on domain expertise\n",
    "- [ ] Integrate with real-time METAR feeds\n",
    "- [ ] Build alerting system for critical anomalies\n",
    "- [ ] Validate with historical incident data"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
